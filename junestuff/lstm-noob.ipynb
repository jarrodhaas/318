{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Inspired by example from\n",
    "https://github.com/Vict0rSch/deep_learning/tree/master/keras/recurrent\n",
    "Uses the TensorFlow backend\n",
    "The basic idea is to detect anomalies in a time-series.\n",
    "\"\"\"\n",
    "import matplotlib as mpl\n",
    "mpl.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "from numpy import arange, sin, pi, random\n",
    "import math\n",
    "np.random.seed(1234)\n",
    "\n",
    "# Global hyper-parameters\n",
    "sequence_length = 100\n",
    "random_data_dup = 5  # each sample randomly duplicated between 0 and 9 times, see dropin function\n",
    "epochs = 1\n",
    "batch_size = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v1 = pd.read_csv('test_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v1.drop('Time', axis=1, inplace=True)\n",
    "v1.drop('Date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v1.sort_index(ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v1 = v1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v1.drop('index',axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v1 = v1.interpolate()\n",
    "#v1.fillna(method='pad') # https://pandas.pydata.org/pandas-docs/stable/missing_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(786422, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v1k = v1[:1000]\n",
    "active_power = v1k.Global_active_power\n",
    "reactive_power = v1k.Global_reactive_power\n",
    "voltage = v1k.Voltage\n",
    "intensity = v1k.Global_intensity\n",
    "metering1 = v1k.Sub_metering_1\n",
    "metering2 = v1k.Sub_metering_2\n",
    "metering3 = v1k.Sub_metering_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# v1.shape (786422, 8)\n",
    "active_power = v1.Global_active_power\n",
    "reactive_power = v1.Global_reactive_power\n",
    "voltage = v1.Voltage\n",
    "intensity = v1.Global_intensity\n",
    "metering1 = v1.Sub_metering_1\n",
    "metering2 = v1.Sub_metering_2\n",
    "metering3 = v1.Sub_metering_3\n",
    "serieses = [active_power, reactive_power, voltage, intensity, metering1, metering2, metering3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# v1.shape (786422, 8)\n",
    "def trim_5(series):\n",
    "    while series.shape[0] % 5 != 0:\n",
    "        series = series.iloc[:-1]\n",
    "    return series\n",
    "def avg_5(series):\n",
    "    name = series.name# + 'div5'\n",
    "    trimmed = trim_5(series)\n",
    "    shaped = trimmed.values.reshape(int(trimmed.shape[0]/5),5)\n",
    "    meaned = shaped.mean(axis=1)\n",
    "    return pd.Series(meaned, name=name)\n",
    "def avg_5_list(serieses):\n",
    "    serieses_avg_5 = []\n",
    "    for eachSeries in serieses:\n",
    "        serieses_avg_5.append(avg_5(eachSeries))\n",
    "    return serieses_avg_5\n",
    "def first_n(serieseses, n):\n",
    "    result = []\n",
    "    for eachSerieses in serieseses:\n",
    "        result.append(eachSerieses[:n])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "serieses_avg_5 = avg_5_list(serieses)\n",
    "serieses_avg_25 = avg_5_list(serieses_avg_5)\n",
    "serieses_avg_125 = avg_5_list(serieses_avg_25)\n",
    "serieses_avg_625 = avg_5_list(serieses_avg_125)\n",
    "#serieses_avg_3125 = avg_5_list(serieses_avg_625)\n",
    "serieseses = [serieses, serieses_avg_5, serieses_avg_25, serieses_avg_125, serieses_avg_625]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ssss_1250 = first_n(serieseses, 1250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot250(serieses, scale_string, offset=0):\n",
    "    plt.figure(1, figsize=(20,20))\n",
    "    seriesCount = len(serieses)\n",
    "    plotCount = seriesCount * 100 + 10\n",
    "    for i, series in enumerate(serieses):\n",
    "        toPlot = series[250*offset:250]\n",
    "        plotPosition = plotCount + i + 1\n",
    "        plt.subplot(plotPosition)\n",
    "        plt.title(series.name + \" Signal at scale: \" + str(scale_string))\n",
    "        plt.plot(series, 'b', alpha=0.6)\n",
    "    plt.savefig(\"plot250_\" + str(scale_string) + \"_offset_\" + str(offset), dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropin(X, y):\n",
    "    \"\"\" The name suggests the inverse of dropout, i.e. adding more samples. See Data Augmentation section at\n",
    "    http://simaaron.github.io/Estimating-rainfall-from-weather-radar-readings-using-recurrent-neural-networks/\n",
    "    :param X: Each row is a training sequence\n",
    "    :param y: Tne target we train and will later predict\n",
    "    :return: new augmented X, y\n",
    "    \"\"\"\n",
    "    print(\"X shape:\", X.shape)\n",
    "    print(\"y shape:\", y.shape)\n",
    "    X_hat = []\n",
    "    y_hat = []\n",
    "    for i in range(0, len(X)):\n",
    "        for j in range(0, np.random.randint(0, random_data_dup)):\n",
    "            X_hat.append(X[i, :])\n",
    "            y_hat.append(y[i])\n",
    "    return np.asarray(X_hat), np.asarray(y_hat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def z_norm_multivariate(series):\n",
    "    series -= series.mean()\n",
    "    series /= series.std()\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def z_norm(result):\n",
    "    result_mean = result.mean()\n",
    "    result_std = result.std()\n",
    "    result -= result_mean\n",
    "    result /= result_std\n",
    "    return result, result_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_split_prep_data(data, train_start, train_end, test_start, test_end):\n",
    "    print(\"Length of Data\", len(data))\n",
    "\n",
    "    # train data\n",
    "    print (\"Creating train data...\")\n",
    "\n",
    "    result = []\n",
    "    for index in range(train_start, train_end - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "    result = np.array(result)  # shape (samples, sequence_length)\n",
    "    result, result_mean = z_norm(result)\n",
    "\n",
    "    print (\"Mean of train data : \", result_mean)\n",
    "    print (\"Train data shape  : \", result.shape)\n",
    "\n",
    "    train = result[train_start:train_end, :]\n",
    "    np.random.shuffle(train)  # shuffles in-place\n",
    "    X_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    X_train, y_train = dropin(X_train, y_train)\n",
    "\n",
    "    # test data\n",
    "    print (\"Creating test data...\")\n",
    "\n",
    "    result = []\n",
    "    for index in range(test_start, test_end - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "    result = np.array(result)  # shape (samples, sequence_length)\n",
    "    result, result_mean = z_norm(result)\n",
    "    \n",
    "    X_test = result[:, :-1]\n",
    "    y_test = result[:, -1]\n",
    "\n",
    "    print(\"Shape X_train\", np.shape(X_train))\n",
    "    print(\"Shape y_train\", np.shape(y_train))\n",
    "    print(\"Shape X_test\", np.shape(X_test))\n",
    "    print(\"Shape y_test\", np.shape(y_test))\n",
    "\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    layers = {'input': 1, 'hidden1': 64, 'hidden2': 256, 'hidden3': 100, 'output': 1}\n",
    "\n",
    "    model.add(LSTM(\n",
    "            input_shape=(sequence_length - 1, layers['input']),\n",
    "            units=layers['hidden1'],\n",
    "            return_sequences=True,\n",
    "            #stateful=True,\n",
    "            #batch_input_shape = (None,sequence_length-1,1)\n",
    "    ))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "            layers['hidden2'],\n",
    "            return_sequences=True,\n",
    "            #stateful=True\n",
    "    ))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "            layers['hidden3'],\n",
    "            return_sequences=False,\n",
    "            #stateful=True\n",
    "    ))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(\n",
    "            units=layers['output']))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
    "    print (\"Compilation Time : \", time.time() - start)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_csv(signal, predicted, mse, title, view_range):\n",
    "    df = pd.DataFrame({title:signal, \"predicted\": predicted, \"mse\":mse})    \n",
    "    df.to_csv(title + '_predicted_mse_'+ str(view_range) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run network\n",
    "def run(series, view_range, scale_string=\"\"):\n",
    "    model = build_model()\n",
    "    data = series.values\n",
    "    title = series.name + \" at scale: \" + scale_string\n",
    "    global_start_time = time.time()\n",
    "    X_train, y_train, X_test, y_test = get_split_prep_data(series.values, 0, view_range, 0, view_range)\n",
    "    try:\n",
    "        print(\"Training...\")\n",
    "        model.fit(\n",
    "                X_train, y_train,\n",
    "                batch_size=batch_size, \n",
    "            epochs=epochs, \n",
    "            validation_split=0.05,\n",
    "            shuffle=False\n",
    "        )\n",
    "        print(\"Predicting...\")\n",
    "        predicted = model.predict(X_test)\n",
    "        print(\"Reshaping predicted\")\n",
    "        predicted = np.reshape(predicted, (predicted.size,))\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"prediction exception\")\n",
    "        print ('Training duration (s) : ', time.time() - global_start_time)\n",
    "\n",
    "    try:\n",
    "        actual_plot = y_test[:len(y_test)]\n",
    "        predicted_plot = predicted[:len(y_test)]\n",
    "        mse = ((y_test - predicted) ** 2)\n",
    "        triplePlot()\n",
    "        mpl.rcParams.update({'font.size': 8})\n",
    "#         plt.clf()\n",
    "#         plt.figure(1, figsize=(30,15))\n",
    "#         plt.subplot(311)\n",
    "#         plt.title(\"Actual Signal With Anomalies: \" + title)\n",
    "#         plt.plot(, 'b', alpha=0.6)\n",
    "#         plt.subplot(312)\n",
    "#         plt.title(\"Predicted Signal\")\n",
    "#         plt.plot(predicted[:len(y_test)], 'g', alpha=0.6)\n",
    "#         plt.subplot(313)\n",
    "#         plt.title(\"Squared Error\")\n",
    "        #plt.plot(mse, 'r', alpha=0.6)\n",
    "        #plt.tight_layout()\n",
    "        #plt.savefig(title + '_lstm_' + '.png' , bbox_inches='tight', dpi=200)\n",
    "        save_csv(y_test[:len(y_test)],predicted[:len(y_test)], mse, title, view_range)\n",
    "    except Exception as e:\n",
    "        print(\"plotting exception\")\n",
    "        print (str(e))\n",
    "    print ('Training duration (s) : ', time.time() - global_start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation Time :  0.05466413497924805\n",
      "Length of Data 1258\n",
      "Creating train data...\n",
      "Mean of train data :  1.3627338794\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1784, 99)\n",
      "Shape y_train (1784,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1694 samples, validate on 90 samples\n",
      "Epoch 1/1\n",
      "1694/1694 [==============================] - 106s - loss: 0.7792 - val_loss: 0.7461\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "Training duration (s) :  137.79941201210022\n",
      "Compilation Time :  0.060101985931396484\n",
      "Length of Data 1258\n",
      "Creating train data...\n",
      "Mean of train data :  0.117135573445\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1854, 99)\n",
      "Shape y_train (1854,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1761 samples, validate on 93 samples\n",
      "Epoch 1/1\n",
      "1761/1761 [==============================] - 115s - loss: 0.8320 - val_loss: 0.7230\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "Training duration (s) :  149.65273189544678\n",
      "Compilation Time :  0.058541059494018555\n",
      "Length of Data 1258\n",
      "Creating train data...\n",
      "Mean of train data :  240.118859563\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1824, 99)\n",
      "Shape y_train (1824,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1732 samples, validate on 92 samples\n",
      "Epoch 1/1\n",
      "1732/1732 [==============================] - 117s - loss: 0.7101 - val_loss: 0.5777\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "Training duration (s) :  152.69864082336426\n",
      "Compilation Time :  0.07852411270141602\n",
      "Length of Data 1258\n",
      "Creating train data...\n",
      "Mean of train data :  4.59447259169\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1840, 99)\n",
      "Shape y_train (1840,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1748 samples, validate on 92 samples\n",
      "Epoch 1/1\n",
      "1748/1748 [==============================] - 126s - loss: 0.8621 - val_loss: 0.4557\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "Training duration (s) :  161.92961812019348\n",
      "Compilation Time :  0.06563997268676758\n",
      "Length of Data 1258\n",
      "Creating train data...\n",
      "Mean of train data :  1.17489320889\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1757, 99)\n",
      "Shape y_train (1757,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1669 samples, validate on 88 samples\n",
      "Epoch 1/1\n",
      "1669/1669 [==============================] - 119s - loss: 0.9599 - val_loss: 0.5829\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "Training duration (s) :  158.3006148338318\n",
      "Compilation Time :  0.07569289207458496\n",
      "Length of Data 1258\n",
      "Creating train data...\n",
      "Mean of train data :  1.41782541333\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1758, 99)\n",
      "Shape y_train (1758,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1670 samples, validate on 88 samples\n",
      "Epoch 1/1\n",
      "1670/1670 [==============================] - 113s - loss: 1.0678 - val_loss: 1.2378\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "Training duration (s) :  147.0828890800476\n",
      "Compilation Time :  0.07900500297546387\n",
      "Length of Data 1258\n",
      "Creating train data...\n",
      "Mean of train data :  6.03786275556\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1780, 99)\n",
      "Shape y_train (1780,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1691 samples, validate on 89 samples\n",
      "Epoch 1/1\n",
      "1691/1691 [==============================] - 115s - loss: 0.9852 - val_loss: 1.2495\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "Training duration (s) :  150.08137702941895\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "active_power = v1k.Global_active_power\n",
    "reactive_power = v1k.Global_reactive_power\n",
    "voltage = v1k.Voltage\n",
    "intensity = v1k.Global_intensity\n",
    "metering1 = v1k.Sub_metering_1\n",
    "metering2 = v1k.Sub_metering_2\n",
    "metering3 = v1k.Sub_metering_3\n",
    "'''\n",
    "#[serieses, serieses_avg_5, serieses_avg_25, serieses_avg_125, serieses_avg_625]\n",
    "for eachSeries in serieses_avg_625:\n",
    "    run(eachSeries, 1000, \"5^\" + \"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compilation Time :  0.10749101638793945\n",
      "Length of Data 786422\n",
      "Creating train data...\n",
      "Mean of train data :  2.56858015278\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1823, 99)\n",
      "Shape y_train (1823,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1731 samples, validate on 92 samples\n",
      "Epoch 1/1\n",
      "1731/1731 [==============================] - 224s - loss: 0.6811 - val_loss: 1.0986\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "Training duration (s) :  280.21554136276245\n",
      "Compilation Time :  0.13102197647094727\n",
      "Length of Data 786422\n",
      "Creating train data...\n",
      "Mean of train data :  0.129359444444\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1738, 99)\n",
      "Shape y_train (1738,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1651 samples, validate on 87 samples\n",
      "Epoch 1/1\n",
      "1651/1651 [==============================] - 206s - loss: 0.2608 - val_loss: 0.1732\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "Training duration (s) :  270.5351061820984\n",
      "Compilation Time :  0.2418520450592041\n",
      "Length of Data 786422\n",
      "Creating train data...\n",
      "Mean of train data :  239.420116889\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1817, 99)\n",
      "Shape y_train (1817,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1726 samples, validate on 91 samples\n",
      "Epoch 1/1\n",
      "1726/1726 [==============================] - 207s - loss: 0.6213 - val_loss: 0.2946\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "Training duration (s) :  261.53398418426514\n",
      "Compilation Time :  0.14103102684020996\n",
      "Length of Data 786422\n",
      "Creating train data...\n",
      "Mean of train data :  3.24813111111\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1774, 99)\n",
      "Shape y_train (1774,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1685 samples, validate on 89 samples\n",
      "Epoch 1/1\n",
      "1685/1685 [==============================] - 166s - loss: 0.2271 - val_loss: 0.1891\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "Training duration (s) :  218.72778606414795\n",
      "Compilation Time :  0.1021580696105957\n",
      "Length of Data 786422\n",
      "Creating train data...\n",
      "Mean of train data :  1.85083333333\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1744, 99)\n",
      "Shape y_train (1744,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1656 samples, validate on 88 samples\n",
      "Epoch 1/1\n",
      "1656/1656 [==============================] - 157s - loss: 0.1078 - val_loss: 0.0099\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "Training duration (s) :  204.32966709136963\n",
      "Compilation Time :  0.09997963905334473\n",
      "Length of Data 786422\n",
      "Creating train data...\n",
      "Mean of train data :  0.426233333333\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1789, 99)\n",
      "Shape y_train (1789,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1699 samples, validate on 90 samples\n",
      "Epoch 1/1\n",
      "1699/1699 [==============================] - 159s - loss: 0.0567 - val_loss: 0.0434\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "Training duration (s) :  210.45086002349854\n",
      "Compilation Time :  0.09303092956542969\n",
      "Length of Data 786422\n",
      "Creating train data...\n",
      "Mean of train data :  6.01996666667\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1869, 99)\n",
      "Shape y_train (1869,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1775 samples, validate on 94 samples\n",
      "Epoch 1/1\n",
      "1775/1775 [==============================] - 138s - loss: 0.1957 - val_loss: 0.0649\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "Training duration (s) :  178.61296391487122\n",
      "Compilation Time :  0.07878494262695312\n",
      "Length of Data 157284\n",
      "Creating train data...\n",
      "Mean of train data :  1.93924437691\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1753, 99)\n",
      "Shape y_train (1753,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1665 samples, validate on 88 samples\n",
      "Epoch 1/1\n",
      "1665/1665 [==============================] - 123s - loss: 0.4272 - val_loss: 0.1701\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "plotting exception\n",
      "[Errno 2] No such file or directory: 'Global_active_power/5 at scale: 5^1_predicted_mse_1000.csv'\n",
      "Training duration (s) :  162.92116618156433\n",
      "Compilation Time :  0.07707905769348145\n",
      "Length of Data 157284\n",
      "Creating train data...\n",
      "Mean of train data :  0.140240093333\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1829, 99)\n",
      "Shape y_train (1829,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1737 samples, validate on 92 samples\n",
      "Epoch 1/1\n",
      "1737/1737 [==============================] - 129s - loss: 0.9599 - val_loss: 1.0793\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "plotting exception\n",
      "[Errno 2] No such file or directory: 'Global_reactive_power/5 at scale: 5^1_predicted_mse_1000.csv'\n",
      "Training duration (s) :  162.5341398715973\n",
      "Compilation Time :  0.05077624320983887\n",
      "Length of Data 157284\n",
      "Creating train data...\n",
      "Mean of train data :  240.323910044\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1822, 99)\n",
      "Shape y_train (1822,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1730 samples, validate on 92 samples\n",
      "Epoch 1/1\n",
      "1730/1730 [==============================] - 135s - loss: 0.7758 - val_loss: 0.4286\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "plotting exception\n",
      "[Errno 2] No such file or directory: 'Voltage/5 at scale: 5^1_predicted_mse_1000.csv'\n",
      "Training duration (s) :  168.8553729057312\n",
      "Compilation Time :  0.09051203727722168\n",
      "Length of Data 157284\n",
      "Creating train data...\n",
      "Mean of train data :  2.592748\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1854, 99)\n",
      "Shape y_train (1854,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1761 samples, validate on 93 samples\n",
      "Epoch 1/1\n",
      "1761/1761 [==============================] - 128s - loss: 0.6567 - val_loss: 0.5736\n",
      "Predicting...\n",
      "Reshaping predicted\n",
      "plotting exception\n",
      "[Errno 2] No such file or directory: 'Global_intensity/5 at scale: 5^1_predicted_mse_1000.csv'\n",
      "Training duration (s) :  166.3714690208435\n",
      "Compilation Time :  0.08066391944885254\n",
      "Length of Data 157284\n",
      "Creating train data...\n",
      "Mean of train data :  0.707431111111\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1813, 99)\n",
      "Shape y_train (1813,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1722 samples, validate on 91 samples\n",
      "Epoch 1/1\n",
      "1722/1722 [==============================] - 128s - loss: 1.0045 - val_loss: 0.1000\n",
      "Predicting...\n",
      "prediction exception\n",
      "Training duration (s) :  148.83782196044922\n",
      "plotting exception\n",
      "local variable 'predicted' referenced before assignment\n",
      "Training duration (s) :  148.83829593658447\n",
      "Compilation Time :  0.05045795440673828\n",
      "Length of Data 157284\n",
      "Creating train data...\n",
      "Mean of train data :  0.419046666667\n",
      "Train data shape  :  (900, 100)\n",
      "X shape: (900, 99)\n",
      "y shape: (900,)\n",
      "Creating test data...\n",
      "Shape X_train (1781, 99)\n",
      "Shape y_train (1781,)\n",
      "Shape X_test (900, 99)\n",
      "Shape y_test (900,)\n",
      "Training...\n",
      "Train on 1691 samples, validate on 90 samples\n",
      "Epoch 1/1\n",
      "1650/1691 [============================>.] - ETA: 2s - loss: 1.5939prediction exception\n",
      "Training duration (s) :  130.95789122581482\n",
      "plotting exception\n",
      "local variable 'predicted' referenced before assignment\n",
      "Training duration (s) :  130.95961713790894\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-5a29558e224b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0meachSeries\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meachSerieses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meachSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"5^\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-33-8e0767ce965d>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(series, view_range, scale_string)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#run network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_string\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" at scale: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscale_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-3c8bf47d39d1>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hidden1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0;31m#stateful=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;31m#batch_input_shape = (None,sequence_length-1,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m                 \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# modify the input spec to include the state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRecurrent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;31m# Actually call the layer, collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    339\u001b[0m                                              \u001b[0mconstants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                                              \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                                              input_length=input_shape[1])\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length)\u001b[0m\n\u001b[1;32m   2536\u001b[0m             \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m             \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2538\u001b[0;31m             swap_memory=True)\n\u001b[0m\u001b[1;32m   2539\u001b[0m         \u001b[0mlast_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m         \u001b[0moutput_ta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)\u001b[0m\n\u001b[1;32m   2768\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWhileContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mback_prop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2769\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2770\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBuildLoop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_invariants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2771\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2597\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2598\u001b[0m       original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2599\u001b[0;31m           pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2600\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2601\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2547\u001b[0m         \u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moriginal_loop_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[0;32m-> 2549\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2550\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m       \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(time, output_ta_t, *states)\u001b[0m\n\u001b[1;32m   2525\u001b[0m                 output, new_states = step_function(current_input,\n\u001b[1;32m   2526\u001b[0m                                                    \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2527\u001b[0;31m                                                    tuple(constants))\n\u001b[0m\u001b[1;32m   2528\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m                     \u001b[0mnew_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, inputs, states)\u001b[0m\n\u001b[1;32m   1145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimplementation\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 \u001b[0mx_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m                 \u001b[0mx_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m                 \u001b[0mx_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m                 \u001b[0mx_o\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_SliceHelper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbegin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m       packed_begin, packed_end, packed_strides = (\n\u001b[0;32m--> 484\u001b[0;31m           stack(begin), stack(end), stack(strides))\n\u001b[0m\u001b[1;32m    485\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0mvar_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m       \u001b[0;31m# If the input is a constant list, it can be converted to a constant op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Input list contains non-constant tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    111\u001b[0m                                          as_ref=False):\n\u001b[1;32m    112\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 102\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    103\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/Documents/tf/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    430\u001b[0m   tensor_proto = tensor_pb2.TensorProto(\n\u001b[1;32m    431\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumpy_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m       tensor_shape=tensor_shape.as_shape(shape).as_proto())\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_same_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnumpy_dtype\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_TENSOR_CONTENT_TYPES\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshape_size\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/tf/lib/python3.6/site-packages/google/protobuf/internal/python_message.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m           \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m       \u001b[0;32melif\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpp_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_FieldDescriptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCPPTYPE_MESSAGE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0mnew_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# v1.shape (786422, 8)\n",
    "scale = 0\n",
    "for i, eachSerieses in enumerate(serieseses):\n",
    "    scale = i\n",
    "    for eachSeries in eachSerieses:\n",
    "        run(eachSeries, 1000, \"5^\" + str(scale))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
